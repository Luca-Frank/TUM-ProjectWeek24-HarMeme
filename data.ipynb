{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/luca/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/luca/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid_memes_18</td>\n",
       "      <td>covid_memes_18.png</td>\n",
       "      <td>[somewhat harmful, individual]</td>\n",
       "      <td>Bernie or Elizabeth?\\nBe informed.Compare them...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid_memes_19</td>\n",
       "      <td>covid_memes_19.png</td>\n",
       "      <td>[somewhat harmful, organization]</td>\n",
       "      <td>Extending the\\nBrexit deadline until\\nOctober ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid_memes_252</td>\n",
       "      <td>covid_memes_252.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>kwai\\ngkwa 0964\\n#nnevvy\\napplause to Thais fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid_memes_255</td>\n",
       "      <td>covid_memes_255.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>So, I order this\\nfoce mask to\\nprotect ogains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid_memes_20</td>\n",
       "      <td>covid_memes_20.png</td>\n",
       "      <td>[somewhat harmful, individual]</td>\n",
       "      <td>best candidate for\\nJA\\n2020\\njoe biden\\nKamal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>covid_memes_5417</td>\n",
       "      <td>covid_memes_5417.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>Jim Halpert\\n@JimHalpert\\neverybody: 2020 is f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>covid_memes_5418</td>\n",
       "      <td>covid_memes_5418.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>litquidity\\nelihcapital\\nyofollewine\\n*covid 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>covid_memes_5419</td>\n",
       "      <td>covid_memes_5419.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>meta\\nMe sending my dog out for supplies since...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>covid_memes_5420</td>\n",
       "      <td>covid_memes_5420.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>People born in March/April in the\\nboveteojoe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>covid_memes_5421</td>\n",
       "      <td>covid_memes_5421.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>Me after washing my hands for 20\\nseconds 57 t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3013 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 image  \\\n",
       "0       covid_memes_18    covid_memes_18.png   \n",
       "1       covid_memes_19    covid_memes_19.png   \n",
       "2      covid_memes_252   covid_memes_252.png   \n",
       "3      covid_memes_255   covid_memes_255.png   \n",
       "4       covid_memes_20    covid_memes_20.png   \n",
       "...                ...                   ...   \n",
       "3008  covid_memes_5417  covid_memes_5417.png   \n",
       "3009  covid_memes_5418  covid_memes_5418.png   \n",
       "3010  covid_memes_5419  covid_memes_5419.png   \n",
       "3011  covid_memes_5420  covid_memes_5420.png   \n",
       "3012  covid_memes_5421  covid_memes_5421.png   \n",
       "\n",
       "                                labels  \\\n",
       "0       [somewhat harmful, individual]   \n",
       "1     [somewhat harmful, organization]   \n",
       "2                        [not harmful]   \n",
       "3                        [not harmful]   \n",
       "4       [somewhat harmful, individual]   \n",
       "...                                ...   \n",
       "3008                     [not harmful]   \n",
       "3009                     [not harmful]   \n",
       "3010                     [not harmful]   \n",
       "3011                     [not harmful]   \n",
       "3012                     [not harmful]   \n",
       "\n",
       "                                                   text  \n",
       "0     Bernie or Elizabeth?\\nBe informed.Compare them...  \n",
       "1     Extending the\\nBrexit deadline until\\nOctober ...  \n",
       "2     kwai\\ngkwa 0964\\n#nnevvy\\napplause to Thais fr...  \n",
       "3     So, I order this\\nfoce mask to\\nprotect ogains...  \n",
       "4     best candidate for\\nJA\\n2020\\njoe biden\\nKamal...  \n",
       "...                                                 ...  \n",
       "3008  Jim Halpert\\n@JimHalpert\\neverybody: 2020 is f...  \n",
       "3009  litquidity\\nelihcapital\\nyofollewine\\n*covid 1...  \n",
       "3010  meta\\nMe sending my dog out for supplies since...  \n",
       "3011  People born in March/April in the\\nboveteojoe ...  \n",
       "3012  Me after washing my hands for 20\\nseconds 57 t...  \n",
       "\n",
       "[3013 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data=[]\n",
    "with open('memes/defaults/annotations/train.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    data.append(result)\n",
    "    #print(f\"result: {result}\")\n",
    "    #print(isinstance(result, dict))\n",
    "    \n",
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_text):\n",
    "    doc = nlp(raw_text)\n",
    "    tokens = []\n",
    "    for token in doc: \n",
    "        if not any([token.is_space, token.is_stop, token.is_punct, \n",
    "                    token.like_num, token.like_url]):\n",
    "            tokens.append(token.lemma_.lower())\n",
    "    return tokens\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Removing stopwords and non-alphanumeric characters\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>processed_text_alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid_memes_18</td>\n",
       "      <td>covid_memes_18.png</td>\n",
       "      <td>[somewhat harmful, individual]</td>\n",
       "      <td>Bernie or Elizabeth?\\nBe informed.Compare them...</td>\n",
       "      <td>bernie elizabeth inform compare issue matter i...</td>\n",
       "      <td>bernie elizabeth issue matter issue make danke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid_memes_19</td>\n",
       "      <td>covid_memes_19.png</td>\n",
       "      <td>[somewhat harmful, organization]</td>\n",
       "      <td>Extending the\\nBrexit deadline until\\nOctober ...</td>\n",
       "      <td>extend brexit deadline october order ensure de...</td>\n",
       "      <td>extending brexit deadline october 31st order e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid_memes_252</td>\n",
       "      <td>covid_memes_252.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>kwai\\ngkwa 0964\\n#nnevvy\\napplause to Thais fr...</td>\n",
       "      <td>kwai gkwa nnevvy applause thais hong kong thai...</td>\n",
       "      <td>kwai gkwa 0964 nnevvy applause thai hong kong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid_memes_255</td>\n",
       "      <td>covid_memes_255.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>So, I order this\\nfoce mask to\\nprotect ogains...</td>\n",
       "      <td>order foce mask protect ogainst fhe corond vir...</td>\n",
       "      <td>order foce mask protect ogainst fhe corond vir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>covid_memes_20</td>\n",
       "      <td>covid_memes_20.png</td>\n",
       "      <td>[somewhat harmful, individual]</td>\n",
       "      <td>best candidate for\\nJA\\n2020\\njoe biden\\nKamal...</td>\n",
       "      <td>good candidate ja joe biden kamala harris bern...</td>\n",
       "      <td>best candidate ja 2020 joe biden kamala harris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>covid_memes_5417</td>\n",
       "      <td>covid_memes_5417.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>Jim Halpert\\n@JimHalpert\\neverybody: 2020 is f...</td>\n",
       "      <td>jim halpert @jimhalpert everybody finally go y...</td>\n",
       "      <td>jim halpert jimhalpert everybody 2020 finally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>covid_memes_5418</td>\n",
       "      <td>covid_memes_5418.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>litquidity\\nelihcapital\\nyofollewine\\n*covid 1...</td>\n",
       "      <td>litquidity elihcapital yofollewine covid sympt...</td>\n",
       "      <td>litquidity elihcapital yofollewine covid 19 sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>covid_memes_5419</td>\n",
       "      <td>covid_memes_5419.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>meta\\nMe sending my dog out for supplies since...</td>\n",
       "      <td>meta send dog supply contract covid-19 coc ma ...</td>\n",
       "      <td>meta sending dog supply since contract coc 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>covid_memes_5420</td>\n",
       "      <td>covid_memes_5420.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>People born in March/April in the\\nboveteojoe ...</td>\n",
       "      <td>people bear march april boveteojoe folee come ...</td>\n",
       "      <td>people born boveteojoe foleing coming week soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>covid_memes_5421</td>\n",
       "      <td>covid_memes_5421.png</td>\n",
       "      <td>[not harmful]</td>\n",
       "      <td>Me after washing my hands for 20\\nseconds 57 t...</td>\n",
       "      <td>wash hand second time day</td>\n",
       "      <td>washing hand 20 second 57 time one day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3013 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 image  \\\n",
       "0       covid_memes_18    covid_memes_18.png   \n",
       "1       covid_memes_19    covid_memes_19.png   \n",
       "2      covid_memes_252   covid_memes_252.png   \n",
       "3      covid_memes_255   covid_memes_255.png   \n",
       "4       covid_memes_20    covid_memes_20.png   \n",
       "...                ...                   ...   \n",
       "3008  covid_memes_5417  covid_memes_5417.png   \n",
       "3009  covid_memes_5418  covid_memes_5418.png   \n",
       "3010  covid_memes_5419  covid_memes_5419.png   \n",
       "3011  covid_memes_5420  covid_memes_5420.png   \n",
       "3012  covid_memes_5421  covid_memes_5421.png   \n",
       "\n",
       "                                labels  \\\n",
       "0       [somewhat harmful, individual]   \n",
       "1     [somewhat harmful, organization]   \n",
       "2                        [not harmful]   \n",
       "3                        [not harmful]   \n",
       "4       [somewhat harmful, individual]   \n",
       "...                                ...   \n",
       "3008                     [not harmful]   \n",
       "3009                     [not harmful]   \n",
       "3010                     [not harmful]   \n",
       "3011                     [not harmful]   \n",
       "3012                     [not harmful]   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Bernie or Elizabeth?\\nBe informed.Compare them...   \n",
       "1     Extending the\\nBrexit deadline until\\nOctober ...   \n",
       "2     kwai\\ngkwa 0964\\n#nnevvy\\napplause to Thais fr...   \n",
       "3     So, I order this\\nfoce mask to\\nprotect ogains...   \n",
       "4     best candidate for\\nJA\\n2020\\njoe biden\\nKamal...   \n",
       "...                                                 ...   \n",
       "3008  Jim Halpert\\n@JimHalpert\\neverybody: 2020 is f...   \n",
       "3009  litquidity\\nelihcapital\\nyofollewine\\n*covid 1...   \n",
       "3010  meta\\nMe sending my dog out for supplies since...   \n",
       "3011  People born in March/April in the\\nboveteojoe ...   \n",
       "3012  Me after washing my hands for 20\\nseconds 57 t...   \n",
       "\n",
       "                                         processed_text  \\\n",
       "0     bernie elizabeth inform compare issue matter i...   \n",
       "1     extend brexit deadline october order ensure de...   \n",
       "2     kwai gkwa nnevvy applause thais hong kong thai...   \n",
       "3     order foce mask protect ogainst fhe corond vir...   \n",
       "4     good candidate ja joe biden kamala harris bern...   \n",
       "...                                                 ...   \n",
       "3008  jim halpert @jimhalpert everybody finally go y...   \n",
       "3009  litquidity elihcapital yofollewine covid sympt...   \n",
       "3010  meta send dog supply contract covid-19 coc ma ...   \n",
       "3011  people bear march april boveteojoe folee come ...   \n",
       "3012                          wash hand second time day   \n",
       "\n",
       "                                     processed_text_alt  \n",
       "0     bernie elizabeth issue matter issue make danke...  \n",
       "1     extending brexit deadline october 31st order e...  \n",
       "2     kwai gkwa 0964 nnevvy applause thai hong kong ...  \n",
       "3     order foce mask protect ogainst fhe corond vir...  \n",
       "4     best candidate ja 2020 joe biden kamala harris...  \n",
       "...                                                 ...  \n",
       "3008  jim halpert jimhalpert everybody 2020 finally ...  \n",
       "3009  litquidity elihcapital yofollewine covid 19 sy...  \n",
       "3010  meta sending dog supply since contract coc 100...  \n",
       "3011  people born boveteojoe foleing coming week soy...  \n",
       "3012             washing hand 20 second 57 time one day  \n",
       "\n",
       "[3013 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"processed_text\"] = data[\"text\"].apply(preprocess).apply(lambda x: \" \".join(x))\n",
    "data[\"processed_text_alt\"] = data['text'].apply(preprocess_text)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['binary_labels'] = np.where(data['labels'].apply(lambda x: 'very harmful' in x), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_preprocessed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
